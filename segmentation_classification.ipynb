{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Habitat mapping of Askania Nova reserve using Sentinel-2 data and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is meant to reproduce mapping (primarily natural) habitats over the Falz-Fein Biosphere Reserve 'Askania Nova' territory. See Prylutskyi & Shapoval (2024) .... for more details.\n",
    "\n",
    "The overall workflow consists of several consecutive steps:\n",
    "\n",
    "1. Set the Environment, define the research area and set parameters for satellite data;\n",
    "2. Access and prepare Sentinel-2 Surface Reflectance optical data;\n",
    "3. Calculate derived statistics;\n",
    "4. Image segmentation using SNIC algorithm, calculate median values of each band for each segment;\n",
    "5. Download segments as an ESRI Shapefile to manual assignment of habitat classes for training data;\n",
    "6. Annotation of segments (polygons) using desktop GIS, prepare geojson with numerical class IDs;\n",
    "7. Upload annotated SNIC segments back to the Earth Engine to sample SNIC segments median image;\n",
    "8. Stratified splitting of sampled data into training and testing subsets;\n",
    "9. Train Random Forest classifier, and assess classification accuracy using testing subsets;\n",
    "10. Classify the image of median values of bands for SNIC segments;\n",
    "11. Export results as *.tiff and *.shp to Google Drive for visual inspection and preparation of publication-quality habitat map.\n",
    "\n",
    "The remote sensing data used is based on Sentinel-2 Surface Reflectance, available through [Google Earth Engine data catalog](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED). Based on the optical bands, we calculate several statistics:\n",
    "\n",
    "1. Surface reflectance of bands 'B2', 'B3', 'B4', 'B8', 'B11', 'B12' Sentinel-2 medianized per band across intervals of March-October (vegetation season) for 2015-2021 years;\n",
    "2. NDVI and NDWI spectral indices medianized across 2015-2021 years for each month from March to October to control phenological signal.\n",
    "\n",
    "As a result, we obtain a 22-band image for further analysis.\n",
    "\n",
    "In the next step, we apply Superpixel clustering based on Simple Non-Iterative Clustering ([SNIC](https://developers.google.com/earth-engine/apidocs/ee-algorithms-image-segmentation-snic)) to our image in order to obtain homogenous groups of pixel likely represent homogenous habitats. We also need to extract the mean bands (cluster averages) from SNIC segmentation, as those data will play as predictors in further supervised classification of segments.\n",
    "\n",
    "To produce training data, we first export vectorized SNIC segmentation to Google Drive, download it, and manually annotate segments with known habitat types in a desktop GIS. After that, `1_shp2geojson.R` script should be run to prepare data to upload back to Earth Engine.\n",
    "\n",
    "As a Supervised classification method, we use a Random Forest with 50 trees and other parameters set to default. Training and testing points are obtained through the stratified split of data sampled from median band values of SNIC segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the necessary libraries and initialize Google Earth Engine API. Authentification might be challenging and depends on how you run the Notebook. Whether it is Google Colab or a local execution via Jupyter Notebook/stand-alone code editor (I used [Positron](https://positron.posit.co/) and also tested in VS Code and Jupyter Lab), it's advisable for the first launch to set Google Chrome as a default web browser and make sure you are logging in to the same Google Account you use for Earth Engine. For me, an authentification went smoothly only in this way. You don't need to repeat manual authentication each time as earthengine-api credentials will be stored locally. However, it is going to require re-authorization from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install geemap geopandas earthengine-api\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Authenticate and initialise Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project = 'ee-olegpril12') # Change 'ee-olegpril12' to your GEE project title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the Areas of Interest. Read polygon borders of the Falz-Fein Biosphere Reserve \"Askania Nova\" from a geojson file and display it on the map to check validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define outer borders\n",
    "geojson_path = './area_of_interest/bzan_borders.geojson'  # Path to GeoJSON\n",
    "\n",
    "# Read and convert the GeoJSON to an Earth Engine feature collection\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "aoi_borders = geemap.geojson_to_ee(gdf.__geo_interface__)\n",
    "\n",
    "# map = geemap.Map()\n",
    "# map.centerObject(aoi_borders, 11)\n",
    "# map.addLayer(aoi_borders, {'color': 'red'}, 'Outer borders')\n",
    "# map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define priors for satellite data -- date range, optical bands, cloud cover percentage.\n",
    "\n",
    "Set functions for cloud/cloud shadows masking for Sentinel-2 Surface Reflectance data. Access Image Collection, and combine optical data with vegetation indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Image Band Names: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'NDVI_3', 'NDWI_3', 'NDVI_4', 'NDWI_4', 'NDVI_5', 'NDWI_5', 'NDVI_6', 'NDWI_6', 'NDVI_7', 'NDWI_7', 'NDVI_8', 'NDWI_8', 'NDVI_9', 'NDWI_9', 'NDVI_10', 'NDWI_10']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f499c2de18dd4e74863cd1937ee6e47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[46.47146654341297, 33.948553692283426], controls=(WidgetControl(options=['position', 'transparent_…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "start_year = 2015\n",
    "end_year = 2021\n",
    "start_month = 3  # March\n",
    "end_month = 10   # October\n",
    "cloud_percentage = 10 # per cent of cloud cover for upper threshold\n",
    "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']  # Optical bands of interest\n",
    "\n",
    "# Function to mask clouds using QA60 band\n",
    "def mask_s2_clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    mask = (\n",
    "        qa.bitwiseAnd(cloud_bit_mask).eq(0)\n",
    "        .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    )\n",
    "    return image.updateMask(mask).divide(10000).copyProperties(image, [\"system:time_start\"])\n",
    "\n",
    "# Filter images by bounds and timestamp\n",
    "s2_sr = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    .filterBounds(aoi_borders)\n",
    "    .filter(ee.Filter.calendarRange(start_year, end_year, 'year'))\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_percentage))\n",
    "    .filter(ee.Filter.notNull(['system:time_start']))  # Filter only images with timestamps\n",
    "    .map(mask_s2_clouds)\n",
    "    .select(bands)\n",
    ")\n",
    "\n",
    "# Calculate median composite for each band\n",
    "median_composite = s2_sr.median()\n",
    "\n",
    "# Function to calculate NDVI or NDWI for a given month\n",
    "def calculate_index_for_month(month, index_name, bands):\n",
    "    filtered = s2_sr.filter(ee.Filter.calendarRange(month, month, 'month'))\n",
    "    index = filtered.map(\n",
    "        lambda image: image.normalizedDifference(bands).rename(f\"{index_name}_{month}\")\n",
    "    )\n",
    "    return index.median()\n",
    "\n",
    "# Generate NDVI and NDWI bands for each month in the range\n",
    "ndvi_bands = []\n",
    "ndwi_bands = []\n",
    "for month in range(start_month, end_month + 1):\n",
    "    ndvi_image = calculate_index_for_month(month, \"NDVI\", ['B8', 'B4'])\n",
    "    ndvi_bands.append(ndvi_image)\n",
    "    ndwi_image = calculate_index_for_month(month, \"NDWI\", ['B8', 'B3'])\n",
    "    ndwi_bands.append(ndwi_image)\n",
    "\n",
    "# Combine median composite, NDVI, and NDWI images for all months\n",
    "final_image = median_composite\n",
    "for ndvi_image, ndwi_image in zip(ndvi_bands, ndwi_bands):\n",
    "    final_image = final_image.addBands(ndvi_image).addBands(ndwi_image)\n",
    "\n",
    "# Get band names to verify\n",
    "band_names = final_image.bandNames().getInfo()\n",
    "print(\"Final Image Band Names:\", band_names)\n",
    "\n",
    "# Visualise the image on the map\n",
    "visualization_params = {\n",
    "    'min': 0.0,\n",
    "    'max': 1.0,\n",
    "    'bands': ['NDVI_4', 'NDVI_5', 'NDVI_9'], \n",
    "}\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi_borders, 10)\n",
    "Map.addLayer(final_image, visualization_params, 'Median Image with NDVI')\n",
    "Map.addLayer(aoi_borders, {'color': 'red'}, 'Outer borders')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visually examine the image and ensure reference for further manual annotation, we can download selected bands to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the desired bands\n",
    "selected_bands = ['B2', 'B3', 'B4', 'B8', 'B11']\n",
    "image_to_export = final_image.select(selected_bands).clip(aoi_borders)\n",
    "\n",
    "# Export the image to local drive\n",
    "out_file = 'sentinel2_2015_2021.tif'\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image = image_to_export,\n",
    "    description = 'Sentinel2MedianExport',\n",
    "    folder = 'GEE_data',\n",
    "    fileNamePrefix = out_file.replace('.tif', ''),\n",
    "    region = aoi_borders.geometry().bounds().getInfo()['coordinates'],\n",
    "    scale = 10,  # Sentinel-2 spatial resolution is 10m for selected bands\n",
    "    maxPixels = 1e13\n",
    ")\n",
    "task.start()\n",
    "\n",
    "# Monitor the export\n",
    "print('Exporting... Check progress at: https://code.earthengine.google.com/tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation and object-oriented classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superpixel clustering based on SNIC (Simple Non-Iterative Clustering). Outputs a band of cluster IDs and the per-cluster averages for each of the input bands. See [documentation](https://developers.google.com/earth-engine/apidocs/ee-algorithms-image-segmentation-snic) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5606dfdf3743a688bf61eb4b31ebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[46.47146654341297, 33.948553692283426], controls=(WidgetControl(options=['position', 'transparent_…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip the image to the Reserve's borders\n",
    "image = final_image.clip(aoi_borders)\n",
    "\n",
    "# Smaller. more homogenous segments\n",
    "snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "    image = image,\n",
    "    size = 10,          # Smaller size for finer segmentation\n",
    "    compactness = 0.05, # Lower compactness for more homogeneous segments\n",
    "    connectivity = 8    # Maintain 8-connectivity for smooth results\n",
    ")\n",
    "\n",
    "# Extract the mean bands (cluster averages) from SNIC segmentation\n",
    "snic_means = snic.select(\n",
    "    [f\"{band}_mean\" for band in image.bandNames().getInfo()]  # Extract mean band names\n",
    ")\n",
    "\n",
    "# Visualise the results\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi_borders, 12)  # Adjust zoom level for your AOI\n",
    "Map.addLayer(\n",
    "    image, \n",
    "    {\"bands\": [\"B4\", \"B3\", \"B2\"], \"min\": 0, \"max\": 0.3}, \n",
    "    \"Input Image\")\n",
    "Map.addLayer(snic.randomVisualizer(), {}, \"SNIC Segmentation\")\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make training data for subsequent supervised classification, we need to download SNIC segments to the local drive, open it in desktop GIS (e.g., [QGIS](https://qgis.org/)), and manually assign habitat attribute to some of them, based on available ground truth data and expert knowledge. After that, we should save annotated SNIC segments into the new Shapefile (./snic_segments_annotated/snic_segments_annotated.shp) and run the `1_shp2geojson.R` script to prepare data to upload back to the Earth Engine. As a result, we must have a snic_segments_annotated.geojson file containing only segments annotated with numerical class labels (variable \"class_id\") stored in the \"./snic_segments_annotated\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SNIC segments into vectors \n",
    "snic_vectors = snic.select(\"clusters\").reduceToVectors(\n",
    "    **{\n",
    "        \"geometryType\": \"polygon\",\n",
    "        \"scale\": 10,  # Scale in metres\n",
    "        \"maxPixels\": 1e13,  # Increase if needed for large areas\n",
    "        \"geometry\": aoi_borders.geometry(),  # Restrict vectors to your AOI\n",
    "    }\n",
    ")\n",
    "\n",
    "# Export SNIC vectors to a shapefile\n",
    "# Define the export task to Google Drive\n",
    "export_task = ee.batch.Export.table.toDrive(\n",
    "    collection = snic_vectors,\n",
    "    description = \"snic_segments\",  # Name of the task\n",
    "    folder = \"EarthEngineExports\",            # Optional: Folder in Google Drive\n",
    "    fileFormat = \"SHP\"                        # Export format (Shapefile)\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "export_task.start()\n",
    "\n",
    "print(\"Task started. Monitor the task at: https://code.earthengine.google.com/tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised classification of SNIC segments using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use annotated SNIC segments as polygon ground truth data at this step. Those data will be used to sample SNIC images, then split in a stratified way to ensure all classes are present in both training and testing datasets, and finally used for training the Random Forest classifier and assessing classification accuracy.\n",
    "\n",
    "I strongly recommend to apply `1_shp2geojson.R` script to convert ESRI Shapefile into a geojson instead of exporting it as geojson using desktop GIS. This ensures geometry validity and assigns a numerical 'class_id' variable to each annotated segment. The latter is required since the Random Forest classification in Earth Engine is only possible with numerical class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features missing 'class_id': 0\n"
     ]
    }
   ],
   "source": [
    "# Load the GeoJSON file containing manually annotated segments\n",
    "geojson_path = './snic_segments_annotated/snic_segments_annotated.geojson'\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Check for missing 'class_num' property\n",
    "missing_class_id = gdf[gdf['class_id'].isna()]\n",
    "print(f\"Number of features missing 'class_id': {len(missing_class_id)}\")\n",
    "\n",
    "if not missing_class_id.empty:\n",
    "    print(missing_class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the annotated segments are converted into an Earth Engine Feature Collection, and the SNIC segments are sampled to obtain point training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the annotated GeoJSON file as a FeatureCollection\n",
    "snic_segments_annotated = geemap.geojson_to_ee(gdf.__geo_interface__)\n",
    "\n",
    "# Define feature properties for supervised classification\n",
    "class_property = 'class_id'  # Numeric code for habitat classes\n",
    "\n",
    "# Sample data from the SNIC means and annotate with class labels\n",
    "sampled_data = snic_means.sampleRegions(\n",
    "    **{\n",
    "        \"collection\": snic_segments_annotated,\n",
    "        \"properties\": [class_property],\n",
    "        \"scale\": 10,  # Match scale of segmentation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Eart Engine allows only a random split of the entire dataset at once based on a new property containing a [column of deterministic pseudorandom numbers](https://developers.google.com/earth-engine/apidocs/ee-featurecollection-randomcolumn?hl=en) added to a Feature Collection. As we can expect a pronounced class imbalance (different habitat types shall not be expected to occupy equal areas), we must apply a stratified split to ensure all classes appear in both training and testing datasets in the right proportion. To do so, we iteratively apply a randomColumn() function to each habitat type subset of sampled data, then merge them and split them by the value in a 'random' property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get unique class IDs from the 'class_id' property and sort them\n",
    "class_ids = sorted(\n",
    "    snic_segments_annotated\n",
    "    .distinct('class_id')  # Get unique class_id values\n",
    "    .aggregate_array('class_id')  # Convert to an array\n",
    "    .getInfo()  # Get the result as a Python list\n",
    ")\n",
    "\n",
    "# Function to create subsets with a random column\n",
    "def create_random_subset(sampled_data, class_id):\n",
    "    \"\"\"\n",
    "    Filters the FeatureCollection by class_id and adds a random column.\n",
    "    \n",
    "    Parameters:\n",
    "    sampled_data (ee.FeatureCollection): The input FeatureCollection.\n",
    "    class_id (int): The class_id to filter by.\n",
    "    \n",
    "    Returns:\n",
    "    ee.FeatureCollection: The filtered FeatureCollection with a random column.\n",
    "    \"\"\"\n",
    "    subset = sampled_data.filter(ee.Filter.eq('class_id', class_id))\n",
    "    subset_with_random = subset.randomColumn()\n",
    "    return subset_with_random\n",
    "\n",
    "# Process each class_id independently and store results in a list\n",
    "subsets = []\n",
    "for class_id in class_ids:\n",
    "    subset = create_random_subset(sampled_data, class_id)\n",
    "    subsets.append(subset)\n",
    "\n",
    "# Merge all subsets into one FeatureCollection\n",
    "merged_fc = ee.FeatureCollection(subsets).flatten()\n",
    "\n",
    "# Split the data into training (60%) and testing (40%)\n",
    "split = 0.6\n",
    "training_fc = merged_fc.filter(ee.Filter.lt('random', split))\n",
    "testing_fc = merged_fc.filter(ee.Filter.gte('random', split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the Earth Engine's limitations, assessing and printing sizes of large Feature Collections might be extremely time-consuming. Thus, we can alternatively take a look at the first features of both splits to check their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data preview:  {'type': 'Feature', 'geometry': None, 'id': '0_326_0', 'properties': {'B11_mean': 0.22084000706672668, 'B12_mean': 0.15764915943145752, 'B2_mean': 0.04814097285270691, 'B3_mean': 0.07108181715011597, 'B4_mean': 0.06846360862255096, 'B8_mean': 0.1573646515607834, 'NDVI_10_mean': 0.32850342988967896, 'NDVI_3_mean': 0.3635842502117157, 'NDVI_4_mean': 0.4189620912075043, 'NDVI_5_mean': 0.4549817144870758, 'NDVI_6_mean': 0.35895782709121704, 'NDVI_7_mean': 0.2976934015750885, 'NDVI_8_mean': 0.34618261456489563, 'NDVI_9_mean': 0.30415549874305725, 'NDWI_10_mean': 0.33459722995758057, 'NDWI_3_mean': 0.3827904462814331, 'NDWI_4_mean': 0.3952062726020813, 'NDWI_5_mean': 0.41949212551116943, 'NDWI_6_mean': 0.3595248758792877, 'NDWI_7_mean': 0.2917270362377167, 'NDWI_8_mean': 0.33239802718162537, 'NDWI_9_mean': 0.32380470633506775, 'class_id': 1, 'random': 0.29864507510115956}}\n",
      "Testing data preview:  {'type': 'Feature', 'geometry': None, 'id': '0_326_4', 'properties': {'B11_mean': 0.22084000706672668, 'B12_mean': 0.15764915943145752, 'B2_mean': 0.04814097285270691, 'B3_mean': 0.07108181715011597, 'B4_mean': 0.06846360862255096, 'B8_mean': 0.1573646515607834, 'NDVI_10_mean': 0.32850342988967896, 'NDVI_3_mean': 0.3635842502117157, 'NDVI_4_mean': 0.4189620912075043, 'NDVI_5_mean': 0.4549817144870758, 'NDVI_6_mean': 0.35895782709121704, 'NDVI_7_mean': 0.2976934015750885, 'NDVI_8_mean': 0.34618261456489563, 'NDVI_9_mean': 0.30415549874305725, 'NDWI_10_mean': 0.33459722995758057, 'NDWI_3_mean': 0.3827904462814331, 'NDWI_4_mean': 0.3952062726020813, 'NDWI_5_mean': 0.41949212551116943, 'NDWI_6_mean': 0.3595248758792877, 'NDWI_7_mean': 0.2917270362377167, 'NDWI_8_mean': 0.33239802718162537, 'NDWI_9_mean': 0.32380470633506775, 'class_id': 1, 'random': 0.6620437014784243}}\n"
     ]
    }
   ],
   "source": [
    "# # Print the sizes of the splits\n",
    "# print(\"Training size:\", training_fc.size().getInfo())\n",
    "# print(\"Testing size:\", testing_fc.size().getInfo())\n",
    "\n",
    "print(\"Training data preview: \", training_fc.first().getInfo())\n",
    "print(\"Testing data preview: \", testing_fc.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Random Forest classfier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "rf_classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "    features = training_fc,\n",
    "    classProperty = class_property,\n",
    "    inputProperties = snic_means.bandNames().getInfo()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate and export the main accuracy metrics as CSV files: overall accuracy, Cohen's Kappa, and confusion matrix. We do it to test datasets and evaluate the quality of prediction.\n",
    "\n",
    "While Earth Engine has an in-built function errorMatrix(), its execution and export are extremely time-consuming. So we apply a workaround as making a prediction over the testing datasets and exporting it to the ./accuracy/classified_test_data.csv, then calculating accuracy metrics using sklearn.metrics Python package, locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting... Check progress at: https://code.earthengine.google.com/tasks\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier with testing data\n",
    "testing_classified = testing_fc.classify(rf_classifier)\n",
    "\n",
    "# Export the image sample feature collection to Drive as a CSV file.\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection = testing_classified.select(['class_id', 'classification']),\n",
    "    description = 'classified_test_data',\n",
    "    folder = \"EarthEngineExports\",\n",
    "    fileFormat = 'CSV',\n",
    ")\n",
    "task.start()\n",
    "\n",
    "print('Exporting... Check progress at: https://code.earthengine.google.com/tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  711     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0  1371     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 11462     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0   259     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0  5465     0     0     0     1     0     0     0     3     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0  3181     0     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   829     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   967     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0 10237     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 13879     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0  5427     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0   283     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0  1926     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0    71     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0     0   181     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0 17754     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0 12087     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0  1177     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   355]]\n",
      "Overall Accuracy: 0.9999543514482003\n",
      "Kappa Coefficient: 0.9999477586951372\n",
      "Confusion matrix saved as confusion_matrix.csv\n",
      "Overall accuracy saved as test_overall_accuracy.csv\n",
      "Kappa coefficient saved as test_kappa.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"./accuracy/classified_test_data.csv\")\n",
    "\n",
    "# Extract the ground truth and predicted classes\n",
    "y_true = data['class_id']  # Reference class (ground truth)\n",
    "y_pred = data['classification']  # Predicted class\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Compute additional accuracy metrics\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Overall Accuracy: {overall_accuracy}\")\n",
    "print(f\"Kappa Coefficient: {kappa}\")\n",
    "\n",
    "# Export confusion matrix to CSV\n",
    "cm_df = pd.DataFrame(cm, index=sorted(data['class_id'].unique()), columns=sorted(data['classification'].unique()))\n",
    "cm_df.to_csv(\"./accuracy/test_confusion_matrix.csv\", index_label=\"Class ID\")\n",
    "print(\"Confusion matrix saved as confusion_matrix.csv\")\n",
    "\n",
    "# Save overall_accuracy to CSV\n",
    "overall_accuracy_df = pd.DataFrame({'Metric': ['Overall Accuracy'], 'Value': [overall_accuracy]})\n",
    "overall_accuracy_df.to_csv(\"./accuracy/test_overall_accuracy.csv\", index=False)\n",
    "print(\"Overall accuracy saved as test_overall_accuracy.csv\")\n",
    "\n",
    "# Save kappa to CSV\n",
    "kappa_df = pd.DataFrame({'Metric': ['Kappa Coefficient'], 'Value': [kappa]})\n",
    "kappa_df.to_csv(\"./accuracy/test_kappa.csv\", index=False)\n",
    "print(\"Kappa coefficient saved as test_kappa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of SNIC segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is the classification of the SNIC segmentation using our trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the classifier to classify all SNIC segments\n",
    "classified_segments = snic_means.classify(rf_classifier).clip(aoi_borders)\n",
    "\n",
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors  # Import the colors module\n",
    "import numpy as np\n",
    "\n",
    "# Get the unique class IDs from the feature collection\n",
    "unique_classes = snic_segments_annotated.aggregate_array('class_id').distinct().getInfo()\n",
    "unique_classes.sort()  # Sort the class IDs for consistency\n",
    "\n",
    "# Generate a dynamic colour palette\n",
    "num_classes = len(unique_classes)\n",
    "palette = plt.cm.get_cmap('tab10', num_classes)  # Use a colormap with enough distinct colours\n",
    "colour_palette = [mcolors.rgb2hex(palette(i)) for i in range(num_classes)]\n",
    "\n",
    "# Define visualisation parameters\n",
    "vis_params = {\n",
    "    \"min\": min(unique_classes),\n",
    "    \"max\": max(unique_classes),\n",
    "    \"palette\": colour_palette,\n",
    "}\n",
    "\n",
    "# Visualise the classification results\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi_borders, 12)\n",
    "Map.addLayer(image, {\"bands\": [\"B4\", \"B3\", \"B2\"], \"min\": 0, \"max\": 0.3}, \"Input Image\")\n",
    "Map.addLayer(snic.randomVisualizer(), {}, \"SNIC Segmentation\")\n",
    "Map.addLayer(\n",
    "    classified_segments,\n",
    "    vis_params,\n",
    "    \"Classified Segments\"\n",
    ")\n",
    "Map.addLayer(aoi_borders, {\"color\": \"white\"}, \"AOI Borders\", False)\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, depending on our needs, we can export classified segmentation into a .tiff and/or .shp file. If one prefers a Shapefile to manual inspection/post-processing, I advise using the `2_postprocessing.R` script afterwards. It contains the pipeline for the re-assignment of text labels, enables visual settings and exports the classification into a publication-ready map. It also processes accuracy metrics to reconcile a unified accuracy report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export classified SNIC segments into a geotiff raster file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GeoTIFF export task\n",
    "geotiff_task = ee.batch.Export.image.toDrive(\n",
    "    **{\n",
    "        \"image\": classified_segments,\n",
    "        \"description\": \"SNIC_Classification\",\n",
    "        \"folder\": \"EarthEngineExports\",\n",
    "        \"fileNamePrefix\": \"classified_segments\",\n",
    "        \"scale\": 10,  # Match segmentation scale\n",
    "        \"region\": aoi_borders.geometry().bounds(),\n",
    "        \"maxPixels\": 1e13,\n",
    "    }\n",
    ")\n",
    "geotiff_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export classified SNIC segments into ESRI Shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting... Check progress at: https://code.earthengine.google.com/tasks\n"
     ]
    }
   ],
   "source": [
    "# Convert classified segments to vectors\n",
    "classified_vectors = classified_segments.reduceToVectors(\n",
    "    **{\n",
    "        \"geometryType\": \"polygon\",\n",
    "        \"scale\": 10,\n",
    "        \"maxPixels\": 1e13,\n",
    "        \"geometry\": aoi_borders.geometry(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the export task to Google Drive\n",
    "export_task = ee.batch.Export.table.toDrive(\n",
    "    collection = classified_vectors,\n",
    "    description = \"ExportClassifiedSegments\", # Name of the task\n",
    "    folder = \"EarthEngineExports\",            # Optional: Folder in Google Drive\n",
    "    fileFormat = \"SHP\"                        # Export format (Shapefile)\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "export_task.start()\n",
    "\n",
    "print('Exporting... Check progress at: https://code.earthengine.google.com/tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel-based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also classify the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8408290174d4ec39f04ae824f8a5dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[46.47146654341297, 33.948553692283426], controls=(WidgetControl(options=['position', 'transparent_…"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the new band names\n",
    "new_band_names = [\n",
    "    'B2_mean', 'B3_mean', 'B4_mean', 'B8_mean', 'B11_mean', 'B12_mean', \n",
    "    'NDVI_3_mean', 'NDWI_3_mean', 'NDVI_4_mean', 'NDWI_4_mean', \n",
    "    'NDVI_5_mean', 'NDWI_5_mean', 'NDVI_6_mean', 'NDWI_6_mean', \n",
    "    'NDVI_7_mean', 'NDWI_7_mean', 'NDVI_8_mean', 'NDWI_8_mean', \n",
    "    'NDVI_9_mean', 'NDWI_9_mean', 'NDVI_10_mean', 'NDWI_10_mean'\n",
    "]\n",
    "\n",
    "# Apply the classifier to classify all SNIC segments\n",
    "classified_pixels = final_image.rename(new_band_names).classify(rf_classifier).clip(aoi_borders)\n",
    "\n",
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors  # Import the colors module\n",
    "import numpy as np\n",
    "\n",
    "# Get the unique class IDs from the feature collection\n",
    "unique_classes = snic_segments_annotated.aggregate_array('class_id').distinct().getInfo()\n",
    "unique_classes.sort()  # Sort the class IDs for consistency\n",
    "\n",
    "# Generate a dynamic colour palette\n",
    "num_classes = len(unique_classes)\n",
    "palette = plt.cm.get_cmap('tab10', num_classes)  # Use a colormap with enough distinct colours\n",
    "colour_palette = [mcolors.rgb2hex(palette(i)) for i in range(num_classes)]\n",
    "\n",
    "# Define visualisation parameters\n",
    "vis_params = {\n",
    "    \"min\": min(unique_classes),\n",
    "    \"max\": max(unique_classes),\n",
    "    \"palette\": colour_palette,\n",
    "}\n",
    "\n",
    "# Visualise the classification results\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi_borders, 12)\n",
    "Map.addLayer(image, {\"bands\": [\"B4\", \"B3\", \"B2\"], \"min\": 0, \"max\": 0.3}, \"Input Image\")\n",
    "# Map.addLayer(snic.randomVisualizer(), {}, \"SNIC Segmentation\")\n",
    "Map.addLayer(\n",
    "    classified_pixels,\n",
    "    vis_params,\n",
    "    \"Classified pixel image\"\n",
    ")\n",
    "Map.addLayer(aoi_borders, {\"color\": \"white\"}, \"AOI Borders\", False)\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export classified image to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define GeoTIFF export task\n",
    "geotiff_task = ee.batch.Export.image.toDrive(\n",
    "    **{\n",
    "        \"image\": classified_pixels,\n",
    "        \"description\": \"Pixel_Classification\",\n",
    "        \"folder\": \"EarthEngineExports\",\n",
    "        \"fileNamePrefix\": \"classified_pixels\",\n",
    "        \"scale\": 10,  # Match segmentation scale\n",
    "        \"region\": aoi_borders.geometry().bounds(),\n",
    "        \"maxPixels\": 1e13,\n",
    "    }\n",
    ")\n",
    "geotiff_task.start()\n",
    "\n",
    "print('Exporting... Check progress at: https://code.earthengine.google.com/tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
